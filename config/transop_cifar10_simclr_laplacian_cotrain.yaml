defaults:
  - simclr_cifar10
  - _self_

exp_name: cotrain_vi_100s

model_cfg:
  header_cfg:
    enable_transop_augmentation: false
    enable_transop_header: true
    transop_header_cfg:
      batch_size: 128
      start_iter: 0
      fine_tune_iter: 0
      dictionary_size: 100
      lambda_prior: 0.01
      transop_weight_decay: 1.0e-5
      transop_lr: 0.001
      enable_dict_per_block: true
      block_dim: 64
      enable_variational_inference: true
      vi_cfg:
        max_sample_start_iter: 0
        samples_per_iter: 100
        total_num_samples: 100
        max_sample_l1_penalty: 0.0
        feature_dim: 512
        scale_prior: 0.01
        shift_prior: 0.0
        variational_encoder_lr: 0.0001
        variational_encoder_weight_decay: 1.0e-5
        enable_learned_prior: false
        enable_thresh_warmup: false
        enable_enc_attn: false
        enable_det_enc: false
  loss_cfg:
    ntxent_loss_active: true
    ntxent_loss_weight: 1.0
    kl_loss_active: true
    kl_loss_weight: 1.0e-5
    kl_detach_shift: true
    kl_weight_warmup: Exponential
    enable_shift_l2: true
    shift_l2_weight: 5.0e-3
    transop_loss_active: true
    transop_loss_weight: 1.0
    transop_loss_fn: mse
    real_eig_reg_active: false

trainer_cfg:
  metric_logger_cfg:
    enable_transop_logging: true
  use_amp: false
  enable_transop_grad_clip: true
  enable_coeffenc_grad_clip: true
  enable_nn_queue: false